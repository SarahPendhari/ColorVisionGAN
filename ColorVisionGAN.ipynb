{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdYfZ_w7uqZ6",
        "outputId": "c0bda0d5-580c-45ef-e314-fcfb4fdf6b96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow matplotlib opencv-python-headless pycocotools wget -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XmSVRp37urN7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import wget\n",
        "import zipfile\n",
        "\n",
        "# Directory where COCO data will be stored\n",
        "dataset_dir = 'coco_dataset'\n",
        "os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "# Download COCO dataset annotations\n",
        "ann_file = 'http://images.cocodataset.org/annotations/annotations_trainval2017.zip'\n",
        "wget.download(ann_file, out=dataset_dir)\n",
        "\n",
        "# Extract annotations\n",
        "with zipfile.ZipFile(os.path.join(dataset_dir, 'annotations_trainval2017.zip'), 'r') as zip_ref:\n",
        "    zip_ref.extractall(dataset_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DB1ufZWut6J",
        "outputId": "a5be1d6d-d791-48bb-c324-96c6857ae438"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.75s)\n",
            "creating index...\n",
            "index created!\n",
            "Train images shape: (100, 256, 256, 3)\n",
            "Train labels shape: (100, 256, 256, 3)\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from pycocotools.coco import COCO\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_and_preprocess_image(image_path, target_size=(256, 256)):\n",
        "    # Load image\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Resize image\n",
        "    image = cv2.resize(image, target_size)\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    gray_image = np.stack([gray_image]*3, axis=-1)  # Stack grayscale to create 3-channel image\n",
        "\n",
        "    # Normalize images\n",
        "    image = image / 127.5 - 1\n",
        "    gray_image = gray_image / 127.5 - 1\n",
        "\n",
        "    return gray_image, image\n",
        "\n",
        "def download_coco_images(data_type='val2017', num_images=100):\n",
        "    # COCO dataset path\n",
        "    ann_file = f'{dataset_dir}/annotations/instances_{data_type}.json'\n",
        "    coco = COCO(ann_file)\n",
        "\n",
        "    # Get image ids and download images\n",
        "    img_ids = coco.getImgIds()\n",
        "    img_ids = random.sample(img_ids, num_images)\n",
        "    img_paths = []\n",
        "    for img_id in img_ids:\n",
        "        img_info = coco.loadImgs(img_id)[0]\n",
        "        img_url = img_info['coco_url']\n",
        "        img_path = f\"{dataset_dir}/{data_type}/{img_info['file_name']}\"\n",
        "        os.makedirs(os.path.dirname(img_path), exist_ok=True)\n",
        "        if not os.path.exists(img_path):\n",
        "            wget.download(img_url, out=os.path.dirname(img_path))\n",
        "        img_paths.append(img_path)\n",
        "    return img_paths\n",
        "\n",
        "# Example: Load images and create training pairs\n",
        "data_type = 'val2017'\n",
        "num_images = 100\n",
        "\n",
        "img_paths = download_coco_images(data_type, num_images)\n",
        "train_images = []\n",
        "train_labels = []\n",
        "\n",
        "for image_path in img_paths:\n",
        "    gray_image, color_image = load_and_preprocess_image(image_path)\n",
        "    train_images.append(gray_image)\n",
        "    train_labels.append(color_image)\n",
        "\n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "print(f\"Train images shape: {train_images.shape}\")\n",
        "print(f\"Train labels shape: {train_labels.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmIE6_5Xu4Og"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, LeakyReLU, Activation, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def build_generator():\n",
        "    inputs = Input(shape=(256, 256, 3))\n",
        "    down1 = Conv2D(64, (4, 4), strides=2, padding='same')(inputs)\n",
        "    down1 = LeakyReLU(alpha=0.2)(down1)\n",
        "\n",
        "    down2 = Conv2D(128, (4, 4), strides=2, padding='same')(down1)\n",
        "    down2 = LeakyReLU(alpha=0.2)(down2)\n",
        "\n",
        "    up1 = Conv2DTranspose(64, (4, 4), strides=2, padding='same')(down2)\n",
        "    up1 = LeakyReLU(alpha=0.2)(up1)\n",
        "\n",
        "    up2 = Conv2DTranspose(3, (4, 4), strides=2, padding='same')(up1)\n",
        "    outputs = Activation('tanh')(up2)\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "def build_discriminator():\n",
        "    inputs = Input(shape=(256, 256, 3))\n",
        "    down1 = Conv2D(64, (4, 4), strides=2, padding='same')(inputs)\n",
        "    down1 = LeakyReLU(alpha=0.2)(down1)\n",
        "\n",
        "    down2 = Conv2D(128, (4, 4), strides=2, padding='same')(down1)\n",
        "    down2 = LeakyReLU(alpha=0.2)(down2)\n",
        "\n",
        "    flat = Conv2D(1, (4, 4), strides=1, padding='valid')(down2)\n",
        "    outputs = Activation('sigmoid')(flat)\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tejU86uvvgD7"
      },
      "outputs": [],
      "source": [
        "def generator_loss(disc_generated_output, gen_output, target):\n",
        "    # Cast tensors to float32\n",
        "    target = tf.cast(target, tf.float32)\n",
        "    gen_output = tf.cast(gen_output, tf.float32)\n",
        "\n",
        "    gan_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(disc_generated_output), disc_generated_output)\n",
        "    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
        "    total_gen_loss = gan_loss + (100 * l1_loss)\n",
        "    return total_gen_loss\n",
        "\n",
        "def discriminator_loss(disc_real_output, disc_generated_output):\n",
        "    # Cast tensors to float32\n",
        "    disc_real_output = tf.cast(disc_real_output, tf.float32)\n",
        "    disc_generated_output = tf.cast(disc_generated_output, tf.float32)\n",
        "\n",
        "    real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(disc_real_output), disc_real_output)\n",
        "    generated_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
        "    total_disc_loss = real_loss + generated_loss\n",
        "    return total_disc_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaBfees9vjaZ"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(input_image, target):\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        # Forward pass\n",
        "        gen_output = generator(input_image, training=True)\n",
        "        disc_real_output = discriminator(target, training=True)\n",
        "        disc_generated_output = discriminator(gen_output, training=True)\n",
        "\n",
        "        # Calculate losses\n",
        "        gen_loss = generator_loss(disc_generated_output, gen_output, target)\n",
        "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "\n",
        "    # Compute gradients\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    # Update weights\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRUlWn-BvmWh"
      },
      "outputs": [],
      "source": [
        "# Define the number of epochs\n",
        "EPOCHS = 100\n",
        "\n",
        "# Load the dataset (assuming train_images and train_labels are already loaded and preprocessed)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=100).batch(1)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
        "    for input_image, target in train_dataset:\n",
        "        train_step(input_image, target)\n",
        "\n",
        "    # Save model every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        generator.save(f'cvg_generator_epoch_{epoch + 1}.h5')\n",
        "        discriminator.save(f'cvg_discriminator_epoch_{epoch + 1}.h5')\n",
        "\n",
        "    # Generate and save images for visualization\n",
        "    for input_image, target in train_dataset.take(1):\n",
        "        generated_image = generator(input_image, training=False)\n",
        "        plt.figure(figsize=(15, 15))\n",
        "\n",
        "        display_list = [input_image[0], generated_image[0], target[0]]\n",
        "        title = ['Input Image', 'Generated Image', 'Target Image']\n",
        "\n",
        "        for i in range(3):\n",
        "            plt.subplot(1, 3, i + 1)\n",
        "            plt.title(title[i])\n",
        "            plt.imshow((display_list[i] * 0.5 + 0.5))\n",
        "            plt.axis('off')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vl0w0cNAv4YG"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Variables to store loss values\n",
        "generator_losses = []\n",
        "discriminator_losses = []\n",
        "\n",
        "def train_step(input_image, target):\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        # Forward pass\n",
        "        gen_output = generator(input_image, training=True)\n",
        "        disc_real_output = discriminator(target, training=True)\n",
        "        disc_generated_output = discriminator(gen_output, training=True)\n",
        "\n",
        "        # Calculate losses\n",
        "        gen_loss = generator_loss(disc_generated_output, gen_output, target)\n",
        "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "\n",
        "    # Compute gradients\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    # Update weights\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    # Store losses\n",
        "    generator_losses.append(gen_loss.numpy())\n",
        "    discriminator_losses.append(disc_loss.numpy())\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
        "    for input_image, target in train_dataset:\n",
        "        train_step(input_image, target)\n",
        "\n",
        "    # Save model every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        generator.save(f'generator_epoch_{epoch + 1}.h5')\n",
        "        discriminator.save(f'discriminator_epoch_{epoch + 1}.h5')\n",
        "\n",
        "    # Generate and save images for visualization\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        for input_image, target in train_dataset.take(1):\n",
        "            generated_image = generator(input_image, training=False)\n",
        "            plt.figure(figsize=(15, 15))\n",
        "\n",
        "            display_list = [input_image[0], generated_image[0], target[0]]\n",
        "            title = ['Input Image', 'Generated Image', 'Target Image']\n",
        "\n",
        "            for i in range(3):\n",
        "                plt.subplot(1, 3, i + 1)\n",
        "                plt.title(title[i])\n",
        "                plt.imshow((display_list[i] * 0.5 + 0.5))\n",
        "                plt.axis('off')\n",
        "            plt.show()\n",
        "\n",
        "# Plot losses\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(generator_losses, label='Generator Loss')\n",
        "plt.plot(discriminator_losses, label='Discriminator Loss')\n",
        "plt.xlabel('Batch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training Losses')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4KAX_TLxBf4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyN6/7UpGEI2wEakzFzKwFp3",
      "gpuType": "L4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
